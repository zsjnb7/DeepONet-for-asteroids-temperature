# The program for training the network: 
# class Train_Dataset is used for data preprocessing, where
# num_sensors: the number of sensors
# num_input: the number of variables
# batchsize
# data_fup: the dataset generated by dataset_making.py

import numpy as np
import torch
import torch.nn as nn
import pickle
from network import SELayer
from network import SELayer_w
from network import Branch1
from network import Branch2
from network import Branch
from network import Trunk
import os

os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"

class Train_Dataset():
    def __init__(self, num_sensors, num_input, batchsize, data_fup):
        self.num_sensors = num_sensors
        self.num_input = num_input
        self.batchsize = batchsize
        self.data_fup = data_fup
        
    def __Z_Score__(self, x):
        mean = np.mean(x)
        std = np.std(x)
        return mean, std, (x-mean)/std
    
    def data_loader(self):
        f_data = np.tile(np.array([self.data_fup[i, 0](np.linspace(0, 2*np.pi, self.num_sensors)) \
                                   for i in range(len(self.data_fup))])[:, np.newaxis, :], (1, self.num_input, 1))
        u_data = np.array([self.data_fup[i, 1](np.linspace(0, 0.1, self.num_input)) for i in range(len(self.data_fup))])
        p_data = np.tile(self.data_fup[:, 2].astype(float)[:, np.newaxis][:, :, np.newaxis], (1, self.num_input, 1))

        mean, std, u_data = self.__Z_Score__(u_data)

        f_train = torch.tensor(f_data).float().cuda()
        p_train = torch.tensor(p_data).float().cuda()
        u_train = torch.tensor(u_data).float().cuda()

        input_train = torch.cat([f_train, p_train], dim=-1)
        output_train = u_train

        train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(\
                                           input_train[:len(input_train)-np.mod(len(input_train), self.batchsize)], \
                                           output_train[:len(input_train)-np.mod(len(input_train), self.batchsize)]), \
                                           batch_size=self.batchsize, shuffle=True)

        y_data = np.tile(np.linspace(0, 0.1, self.num_input)[np.newaxis, :], (self.batchsize, 1))
        y_train = torch.tensor(y_data).float().cuda().unsqueeze(2)
        return train_loader, y_train
    
if __name__ == '__main__':
    __spec__ = "ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>)"
    
    # Important!
    # Before running this program, the data_fup needs to be imported.
    
    # data_fup is generated by dataset_making.py
    # Dimension is [batch, 3], where 3 are
    # [Random_interp_func, pde_num_u, p]
    # Random_interp_func: the interpolation function of random radiation flux
    # pde_num_u: the interpolation function of temperature about deepth
    # p: random thermal parameter
    
    # This is an example
    data = []
    folder_path = f'dataset/test_data'
    pkl_files = [f for f in os.listdir(folder_path) if f.endswith('.pkl')]
    for file in pkl_files:
        with open(os.path.join(folder_path, file), 'rb') as f:
            data_mid = pickle.load(f)
            data_mid = [x for x in data_mid if x is not None]
            data.append(data_mid)

    data_fup_list = []
    for i in range(len(data)):
        data_fup_list.append(np.array(data[i]))
    data_fup = np.array([item for sublist in data_fup_list for item in sublist])
    
    num_sensors = 128
    num_input = 128
    batchsize = 400
    
    traindataset = Train_Dataset(num_sensors, num_input, batchsize, data_fup)
    train_loader, y_train = traindataset.data_loader()
    
    # import the network
    branch = Branch(num_sensors).cuda()
    branch._initialize_weights()
    trunk = Trunk().cuda()
    trunk._initialize_weights()
    opt = torch.optim.Adam(params=list(branch.parameters())+list(trunk.parameters()), lr=1e-3, betas=(0.8, 0.99))
    loss = nn.MSELoss()

    branch.train();
    trunk.train();
    
    loss_store = []
    for ep in range(300): # The epoches can be changed
        for train_input, train_output in train_loader:
        
            out_branch = branch(train_input[:, :, :-1], train_input[:, :, -1].unsqueeze(2))
            out_trunk = trunk(y_train)
            
            Guy = torch.mean(out_branch*out_trunk, dim=-1)+0.001
            mseloss = loss(Guy, train_output)
        
            loss_store.append(float(mseloss.cpu()))

            opt.zero_grad()
            mseloss.backward()
            opt.step()

        p = ep/(300)
        for param_groups in opt.param_groups:
            param_groups['lr'] = 1e-3/(1+15*p)**0.75
        
        if ep%10==0:
            print('loss_%depoches ='%ep, mseloss.cpu().detach().numpy())
            
    # Here you can add
    # torch.save(branch, "branch_net.pkl")
    # torch.save(trunk, "trunk_net.pkl")
    # to save the after-training network for application
